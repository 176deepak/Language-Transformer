{"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyODivtm3Zt+HxsclhKnhluj"},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"accelerator":"GPU","kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30746,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<center style=\"font-size: 50px; font-family: Times New Roman; font-weight: bold\">Transformer from scratch using Pytorch</center>","metadata":{"id":"ZPy5TthzTLZx"}},{"cell_type":"markdown","source":"<div style=\"text-align: center; background-color:white;\">\n    <img src=\"https://production-media.paperswithcode.com/methods/new_ModalNet-21.jpg\" alt=\"a title\" width=\"300\" height=\"100\">\n</div>","metadata":{"id":"B7w2MjAfTPxO"}},{"cell_type":"code","source":"# ignore all the unwanted warnings\nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{"id":"bEkTIh7LP6m5","executionInfo":{"status":"ok","timestamp":1722873369231,"user_tz":-330,"elapsed":1056,"user":{"displayName":"Deepak Saini","userId":"03922704807803004475"}},"execution":{"iopub.status.busy":"2024-08-07T05:19:15.685658Z","iopub.execute_input":"2024-08-07T05:19:15.686576Z","iopub.status.idle":"2024-08-07T05:19:15.712139Z","shell.execute_reply.started":"2024-08-07T05:19:15.686531Z","shell.execute_reply":"2024-08-07T05:19:15.711090Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"# load modules/libraries\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.utils.data as data\nimport math\nimport copy\nimport numpy as np","metadata":{"id":"xzHtNQJ_QP84","executionInfo":{"status":"ok","timestamp":1722873374220,"user_tz":-330,"elapsed":3901,"user":{"displayName":"Deepak Saini","userId":"03922704807803004475"}},"execution":{"iopub.status.busy":"2024-08-07T05:19:15.714124Z","iopub.execute_input":"2024-08-07T05:19:15.714522Z","iopub.status.idle":"2024-08-07T05:19:18.881249Z","shell.execute_reply.started":"2024-08-07T05:19:15.714486Z","shell.execute_reply":"2024-08-07T05:19:18.880178Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"<center style=\"font-size: 25px; font-family: Times New Roman; font-weight: bold\">Translation Dataset</center>","metadata":{}},{"cell_type":"code","source":"english = [\"Hello, how are you?\"]\nhindi = [\"नमस्ते, आप कैसे हैं?\"]\n    \nsrc_corpus = \" \".join(english)\ntgt_corpus = \" \".join(hindi)\n    \nsrc_vocabulary = src_corpus.split()\nsrc_dictionary = {word: pos for pos, word in enumerate(src_vocabulary)}\n\ntgt_vocabulary = tgt_corpus.split()\ntgt_dictionary = {word: pos for pos, word in enumerate(tgt_vocabulary)}\n\nr_tgt_dictionary = {i:word for word, i in tgt_dictionary.items()}","metadata":{"execution":{"iopub.status.busy":"2024-08-07T08:08:13.597906Z","iopub.execute_input":"2024-08-07T08:08:13.598643Z","iopub.status.idle":"2024-08-07T08:08:13.604957Z","shell.execute_reply.started":"2024-08-07T08:08:13.598610Z","shell.execute_reply":"2024-08-07T08:08:13.603725Z"},"trusted":true},"execution_count":98,"outputs":[]},{"cell_type":"markdown","source":"<center style=\"font-size: 25px; font-family: Times New Roman; font-weight: bold\">Encoder Input Components</center>","metadata":{}},{"cell_type":"code","source":"d_model = 8                                                 # embedding dimension","metadata":{"execution":{"iopub.status.busy":"2024-08-07T06:51:34.087012Z","iopub.execute_input":"2024-08-07T06:51:34.087916Z","iopub.status.idle":"2024-08-07T06:51:34.092065Z","shell.execute_reply.started":"2024-08-07T06:51:34.087883Z","shell.execute_reply":"2024-08-07T06:51:34.091062Z"},"trusted":true},"execution_count":52,"outputs":[]},{"cell_type":"markdown","source":"### Tokenization","metadata":{}},{"cell_type":"code","source":"# Tokens\nip_sne = english[0]\nip_tkns = ip_sne.split()\nnum_tkns = [src_dictionary[tkn] for tkn in ip_tkns]\nprint(f\"Word Tokens: {ip_tkns}\")\nprint(f\"Word to Index: {num_tkns}\")","metadata":{"execution":{"iopub.status.busy":"2024-08-07T06:50:07.051684Z","iopub.execute_input":"2024-08-07T06:50:07.052059Z","iopub.status.idle":"2024-08-07T06:50:07.058032Z","shell.execute_reply.started":"2024-08-07T06:50:07.052032Z","shell.execute_reply":"2024-08-07T06:50:07.056996Z"},"trusted":true},"execution_count":51,"outputs":[{"name":"stdout","text":"Word Tokens: ['Hello,', 'how', 'are', 'you?']\nWord to Index: [0, 1, 2, 3]\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Word Embedding","metadata":{}},{"cell_type":"code","source":"vocab_size = len(src_vocabulary)                            # Total words in vocabulary\nebdg_lyr = nn.Embedding(vocab_size, d_model)                # generates the embedding for given token    \n\nwrd_ebds = []                                               # all tokens' embedding\nfor tkn in num_tkns:\n    ebd = ebdg_lyr(torch.tensor(tkn))\n    wrd_ebds.append(ebd)\n\nprint(f\"{ip_tkns[0]} embedding: {wrd_ebds[0].tolist()}\")\nprint()\nprint(f\"{ip_tkns[1]} embedding: {wrd_ebds[1].tolist()}\")","metadata":{"execution":{"iopub.status.busy":"2024-08-07T06:52:49.562403Z","iopub.execute_input":"2024-08-07T06:52:49.563713Z","iopub.status.idle":"2024-08-07T06:52:49.570583Z","shell.execute_reply.started":"2024-08-07T06:52:49.563679Z","shell.execute_reply":"2024-08-07T06:52:49.569588Z"},"trusted":true},"execution_count":54,"outputs":[{"name":"stdout","text":"Hello, embedding: [-0.9397754669189453, -0.751417875289917, 1.698652744293213, -1.1321967840194702, -0.19192473590373993, -0.33042582869529724, -0.10228903591632843, -0.26329025626182556]\n\nhow embedding: [0.1551840752363205, 1.466767430305481, 1.4544599056243896, 0.4266636371612549, -0.4274609386920929, 0.5144870281219482, -0.06327193975448608, -1.214971661567688]\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Positional Encoding","metadata":{}},{"cell_type":"markdown","source":"<div style=\"text-align: center; background-color:white;\">\n    <img src=\"https://miro.medium.com/v2/resize:fit:1044/1*fX8TN02pB5G1pLNsJIC6QA.png\" alt=\"a title\" width=\"300\" height=\"100\">\n</div>","metadata":{}},{"cell_type":"code","source":"psnl_encs = []                                                        # positional encodings of word embeddings\n\nfor pos, ebd in enumerate(wrd_ebds):\n    d_enc = []                                                        # encoding by dimensions \n    for i in range(0, d_model//2):                                    # 0 <= i < d_model/2\n        deno = math.pow(10000, (2*i)/d_model)                         # denominator term => 10000^(2i/d_model)\n        evn_pos_v = np.sin(pos/deno)                                  # sine value for even positions\n        d_enc.append(evn_pos_v)                \n        \n        odd_pos_v = np.cos(pos/deno)                                  # cosine value for odd positions\n        d_enc.append(odd_pos_v)\n    \n    psnl_encs.append(d_enc)                                           # add each word initial positional encodings         \npsnl_encs = torch.tensor(psnl_encs)\n\n\nfor pos, wrd_ebd in enumerate(wrd_ebds):\n    psnl_encs[pos] = psnl_encs[pos] + wrd_ebd                         # positional encoding = word embedding + initial positional encoding\n    \nprint(f\"{ip_tkns[0]} Positional Encoding: {psnl_encs[0].tolist()}\")\nprint()\nprint(f\"{ip_tkns[1]} Positional Encoding: {psnl_encs[1].tolist()}\")","metadata":{"execution":{"iopub.status.busy":"2024-08-07T06:54:39.056738Z","iopub.execute_input":"2024-08-07T06:54:39.057093Z","iopub.status.idle":"2024-08-07T06:54:39.066386Z","shell.execute_reply.started":"2024-08-07T06:54:39.057065Z","shell.execute_reply":"2024-08-07T06:54:39.065343Z"},"trusted":true},"execution_count":56,"outputs":[{"name":"stdout","text":"Hello, Positional Encoding: [-0.9397754669189453, 0.248582124710083, 1.698652744293213, -0.13219678401947021, -0.19192473590373993, 0.6695741713047028, -0.10228903591632843, 0.7367097437381744]\n\nhow Positional Encoding: [0.996655060044217, 2.0070697361736207, 1.5542933222712179, 1.4216678024392806, -0.41746110535792624, 1.5144370285386135, -0.06227193992115274, -0.2149721615676463]\n","output_type":"stream"}]},{"cell_type":"markdown","source":"<center style=\"font-size: 25px; font-family: Times New Roman; font-weight: bold\">Encoder Mechanism Components</center>","metadata":{}},{"cell_type":"markdown","source":"### Self Attention","metadata":{}},{"cell_type":"markdown","source":"<div style=\"text-align: center; background-color:white;\">\n    <img src=\"https://miro.medium.com/v2/resize:fit:920/1*3eAlr3AEQpoZ9voSp1TstQ.png\" alt=\"a title\" width=\"300\" height=\"100\">\n</div>","metadata":{}},{"cell_type":"code","source":"##### Wq, Wk, Wv matrix of parameters for generating the Q, K, V vectors\nWq = nn.Linear(d_model, d_model, dtype=torch.float64)\nWk = nn.Linear(d_model, d_model, dtype=torch.float64)\nWv = nn.Linear(d_model, d_model, dtype=torch.float64)\n\nQ, K, V = [], [], []                                                   # Matrix for all Query, Key and Value vectors\nfor ebd in psnl_encs:\n    q = Wq(ebd)\n    Q.append(q)\n    \n    k = Wk(ebd)\n    K.append(k)\n    \n    v = Wv(ebd)\n    V.append(v)\n\nQ = torch.stack(Q, dim=0)                                              # Stacked all Query vector as matrix\nK = torch.stack(K, dim=0)                                              # Stacked all Key vector as matrix\nV = torch.stack(V, dim=0)                                              # Stacked all Value vector as matrix\n\nd_k = d_model                                                          # dimensionality of Key vector\n\n# calculate QK_T\nQK_T = torch.matmul(Q, torch.t(K))                \nsld_QK_T = QK_T/math.sqrt(d_k)                                         # scaled dot product of QK_T by sqrt(d_k)\nsoft_QK_T = torch.softmax(sld_QK_T, dim=-1)                            # apply softmax\nself_attn = torch.matmul(soft_QK_T, V)         \n\nprint(f\"Self Attention on {ip_tkns[0]}: {self_attn[0].tolist()}\")\nprint()\nprint(f\"Self Attention on {ip_tkns[1]}: {self_attn[1].tolist()}\")","metadata":{"execution":{"iopub.status.busy":"2024-08-07T06:56:09.070678Z","iopub.execute_input":"2024-08-07T06:56:09.071094Z","iopub.status.idle":"2024-08-07T06:56:09.084083Z","shell.execute_reply.started":"2024-08-07T06:56:09.071063Z","shell.execute_reply":"2024-08-07T06:56:09.083060Z"},"trusted":true},"execution_count":57,"outputs":[{"name":"stdout","text":"Self Attention on Hello,: [-0.11540083527637228, -0.7728133724431447, -0.3088951026179383, -0.5082695126283093, -1.24005988583988, -0.5787977238577567, 0.46306246460804634, 0.014817102869968141]\n\nSelf Attention on how: [-0.11636640240634882, -0.7819564715518782, -0.3233943365215331, -0.523987304255661, -1.268926464963557, -0.5916178181033684, 0.4697221668608989, 0.03930105218907754]\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### MultiHead Attention","metadata":{}},{"cell_type":"markdown","source":"<div style=\"text-align: center; background-color:white;\">\n    <img src=\"https://production-media.paperswithcode.com/methods/multi-head-attention_l1A3G7a.png\" alt=\"a title\" width=\"300\" height=\"100\">\n</div>","metadata":{}},{"cell_type":"markdown","source":"#### For simplicity we assume only 2 heads of Self Attention for Multihead Attention","metadata":{}},{"cell_type":"code","source":"'''*****************************************************: First Head :*****************************************************'''\n##### Wq, Wk, Wv matrix of parameters for generating the Q, K, V vectors\nWq_1 = nn.Linear(d_model, d_model, dtype=torch.float64)\nWk_1 = nn.Linear(d_model, d_model, dtype=torch.float64)\nWv_1 = nn.Linear(d_model, d_model, dtype=torch.float64)\n\nQ_1, K_1, V_1 = [], [], []                                                   # Matrix for all Query, Key and Value vectors\nfor ebd in psnl_encs:\n    q = Wq_1(ebd)\n    Q_1.append(q)\n    \n    k = Wk_1(ebd)\n    K_1.append(k)\n    \n    v = Wv_1(ebd)\n    V_1.append(v)\n\nQ_1 = torch.stack(Q_1, dim=0)                                              # Stacked all Query vector as matrix\nK_1 = torch.stack(K_1, dim=0)                                              # Stacked all Key vector as matrix\nV_1 = torch.stack(V_1, dim=0)                                              # Stacked all Value vector as matrix\n\nd_k = d_model                                                          # dimensionality of Key vector\n\n# calculate QK_T\nQK_T_1 = torch.matmul(Q_1, torch.t(K_1))                \nsld_QK_T_1 = QK_T_1/math.sqrt(d_k)                                         # scaled dot product of QK_T by sqrt(d_k)\nsoft_QK_T_1 = torch.softmax(sld_QK_T_1, dim=-1)                            # apply softmax\nself_attn_1 = torch.matmul(soft_QK_T_1, V_1)         \n'''***************************************************: First Head End :***************************************************'''\n\n'''*****************************************************: Second Head :****************************************************'''\n##### Wq, Wk, Wv matrix of parameters for generating the Q, K, V vectors\nWq_2 = nn.Linear(d_model, d_model, dtype=torch.float64)\nWk_2 = nn.Linear(d_model, d_model, dtype=torch.float64)\nWv_2 = nn.Linear(d_model, d_model, dtype=torch.float64)\n\nQ_2, K_2, V_2 = [], [], []                                                   # Matrix for all Query, Key and Value vectors\nfor ebd in psnl_encs:\n    q = Wq_2(ebd)\n    Q_2.append(q)\n    \n    k = Wk_2(ebd)\n    K_2.append(k)\n    \n    v = Wv_2(ebd)\n    V_2.append(v)\n\nQ_2 = torch.stack(Q_2, dim=0)                                              # Stacked all Query vector as matrix\nK_2 = torch.stack(K_2, dim=0)                                              # Stacked all Key vector as matrix\nV_2 = torch.stack(V_2, dim=0)                                              # Stacked all Value vector as matrix\n\nd_k = d_model                                                          # dimensionality of Key vector\n\n# calculate QK_T\nQK_T_2 = torch.matmul(Q_2, torch.t(K_2))                \nsld_QK_T_2 = QK_T_2/math.sqrt(d_k)                                         # scaled dot product of QK_T by sqrt(d_k)\nsoft_QK_T_2 = torch.softmax(sld_QK_T_2, dim=-1)                            # apply softmax\nself_attn_2 = torch.matmul(soft_QK_T_2, V)         \n'''***************************************************: Second Head End :**************************************************'''\n\n# concatenate both the self attention embeddings\nct_attn = torch.cat((self_attn_1, self_attn_2), 1)\n\n# apply linear transformation\nW_c = nn.Linear(ct_attn.shape[1], d_model, dtype=torch.float64)\n\nmultihead_attn = W_c(ct_attn)\n\nprint(f\"MultiHead Attention on {ip_tkns[0]}: {multihead_attn[0].tolist()}\")\nprint()\nprint(f\"MultiHead Attention on {ip_tkns[1]}: {multihead_attn[1].tolist()}\")","metadata":{"execution":{"iopub.status.busy":"2024-08-07T06:56:44.226586Z","iopub.execute_input":"2024-08-07T06:56:44.226945Z","iopub.status.idle":"2024-08-07T06:56:44.246059Z","shell.execute_reply.started":"2024-08-07T06:56:44.226919Z","shell.execute_reply":"2024-08-07T06:56:44.244939Z"},"trusted":true},"execution_count":59,"outputs":[{"name":"stdout","text":"MultiHead Attention on Hello,: [-0.023973938862265287, 0.04155674399469244, -0.02479283062500319, -0.07631544042817404, 0.2267751287121317, -0.3596756759025933, 0.14273770078297232, -0.09438905317559945]\n\nMultiHead Attention on how: [-0.04706596701729221, 0.07895212595552134, -0.004185196714070014, -0.11031068988956347, 0.2675477194032071, -0.336279049440434, 0.17618500779841367, -0.1270560167661626]\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### MultiHead Attention + Add & Norm","metadata":{}},{"cell_type":"code","source":"# Normalize(O/P MultiHead Attention + Positional Encodings)\nadd_attn = multihead_attn + psnl_encs\n\n# normalization layer\nnorm_l = nn.LayerNorm(d_model, dtype=torch.float64)\n\nnorm_ebds = norm_l(add_attn)\n\nprint(f\"Normalized Embedding of {ip_tkns[0]}: {norm_ebds[0].tolist()}\")\nprint()\nprint(f\"Normalized Embedding of {ip_tkns[1]}: {norm_ebds[1].tolist()}\")","metadata":{"execution":{"iopub.status.busy":"2024-08-07T06:56:58.286634Z","iopub.execute_input":"2024-08-07T06:56:58.287016Z","iopub.status.idle":"2024-08-07T06:56:58.296689Z","shell.execute_reply.started":"2024-08-07T06:56:58.286986Z","shell.execute_reply":"2024-08-07T06:56:58.295714Z"},"trusted":true},"execution_count":60,"outputs":[{"name":"stdout","text":"Normalized Embedding of Hello,: [-1.6938680200926948, 0.08920712711974482, 2.0569092391444808, -0.6198930291081951, -0.2738224553422061, 0.11730604151198197, -0.2658615070045281, 0.5900226037714165]\n\nNormalized Embedding of how: [0.13801448012055995, 1.5329489579299709, 0.87513217492175, 0.5820730264082029, -1.2115892606973535, 0.41857539705642693, -0.8877508193796517, -1.4474039563599042]\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Feed Forward + Addition & Normalization","metadata":{}},{"cell_type":"code","source":"# 2 layer feed forward network\n# 1 layer activation ---> relu\n# 2 lauer activation ---> linear\nfc1 = nn.Linear(d_model, 2048, dtype=torch.float64)\nfc2 = nn.Linear(2048, d_model, dtype=torch.float64)\nfc1_atv = nn.ReLU()\n\nfc_ebds = []\nfor ebd in norm_ebds:\n    fc_ebd = fc2(fc1_atv(fc1(ebd)))\n    \n    fc_ebds.append(fc_ebd)\nfc_ebds = torch.stack(fc_ebds, dim=0)\n\n# Normalized Embeddings + FC Network Embedding\nebds = norm_ebds + fc_ebds\n\n# Normalized Embeddings\nnorm_l = nn.LayerNorm(d_model, dtype=torch.float64)\ne_norm_ebds = norm_l(ebds)\nprint(f\"Normalized Embedding of {ip_tkns[0]}: {e_norm_ebds[0].tolist()}\")\nprint()\nprint(f\"Normalized Embedding of {ip_tkns[1]}: {e_norm_ebds[1].tolist()}\")","metadata":{"execution":{"iopub.status.busy":"2024-08-07T06:57:29.351560Z","iopub.execute_input":"2024-08-07T06:57:29.351959Z","iopub.status.idle":"2024-08-07T06:57:29.363984Z","shell.execute_reply.started":"2024-08-07T06:57:29.351931Z","shell.execute_reply":"2024-08-07T06:57:29.362936Z"},"trusted":true},"execution_count":61,"outputs":[{"name":"stdout","text":"Normalized Embedding of Hello,: [-1.5977213990549342, 0.2631307972251235, 1.9878160556149234, -0.7780540218213827, 0.09604315129400895, 0.333180174899737, -0.7243160447433891, 0.4199212865859132]\n\nNormalized Embedding of how: [-0.08706379767271669, 1.5220678891994877, 0.9713555333059934, 0.6688357751029529, -0.891943047104795, 0.393775352442499, -1.3710556094616986, -1.2059720958117226]\n","output_type":"stream"}]},{"cell_type":"code","source":"e_norm_ebds   # final encoder output","metadata":{"execution":{"iopub.status.busy":"2024-08-07T06:57:39.031993Z","iopub.execute_input":"2024-08-07T06:57:39.032914Z","iopub.status.idle":"2024-08-07T06:57:39.041374Z","shell.execute_reply.started":"2024-08-07T06:57:39.032877Z","shell.execute_reply":"2024-08-07T06:57:39.040094Z"},"trusted":true},"execution_count":62,"outputs":[{"execution_count":62,"output_type":"execute_result","data":{"text/plain":"tensor([[-1.5977,  0.2631,  1.9878, -0.7781,  0.0960,  0.3332, -0.7243,  0.4199],\n        [-0.0871,  1.5221,  0.9714,  0.6688, -0.8919,  0.3938, -1.3711, -1.2060],\n        [-1.2574, -1.0808, -0.3093,  1.5834,  0.8345,  1.0326, -0.9321,  0.1292],\n        [-1.4462, -1.2725, -0.2780, -0.1909,  1.8371,  0.2640,  0.8085,  0.2780]],\n       dtype=torch.float64, grad_fn=<NativeLayerNormBackward0>)"},"metadata":{}}]},{"cell_type":"markdown","source":"<center style=\"font-size: 25px; font-family: Times New Roman; font-weight: bold\">Decoder Mechanism Components</center>","metadata":{}},{"cell_type":"markdown","source":"### Output Input(Only for Training)","metadata":{}},{"cell_type":"code","source":"# same as encoder input\n\n# Tokens\nop_ip_sne = hindi[0] \nop_ip_tkns = op_ip_sne.split()\nnum_tkns = [tgt_dictionary[tkn] for tkn in op_ip_tkns]\nprint(f\"Word Tokens: {op_ip_tkns}\")\nprint(f\"Word to Index: {num_tkns}\")\n\nprint(\"\\n********************************************************************************************************************\\n\")\n\nvocab_size = len(tgt_vocabulary)                                                        # Total words in vocabulary\nebdg_lyr = nn.Embedding(vocab_size, d_model)            # generates the embedding for given token    \n\nwrd_ebds = []                                           # all tokens' embedding\nfor tkn in num_tkns:\n    ebd = ebdg_lyr(torch.tensor(tkn))\n    wrd_ebds.append(ebd)\n\nprint(f\"{op_ip_tkns[0]} embedding: {wrd_ebds[0].tolist()}\")\nprint(f\"{op_ip_tkns[1]} embedding: {wrd_ebds[1].tolist()}\")\n\nprint(\"\\n********************************************************************************************************************\\n\")\n\npsnl_encs = []         # positional encodings of word embeddings\n\nfor pos, ebd in enumerate(wrd_ebds):\n    d_enc = []              # encoding by dimensions \n    for i in range(0, d_model//2):          # 0 <= i < d_model/2\n        deno = math.pow(10000, (2*i)/d_model)            # denominator term => 10000^(2i/d_model)\n        evn_pos_v = np.sin(pos/deno)        # sine value for even positions\n        d_enc.append(evn_pos_v)                \n        \n        odd_pos_v = np.cos(pos/deno)        # cosine value for odd positions\n        d_enc.append(odd_pos_v)\n    \n    psnl_encs.append(d_enc)             # add each word initial positional encodings         \npsnl_encs = torch.tensor(psnl_encs)\n\n\nfor pos, wrd_ebd in enumerate(wrd_ebds):\n    psnl_encs[pos] = psnl_encs[pos] + wrd_ebd         # positional encoding = word embedding + initial positional encoding\n    \nprint(f\"{op_ip_tkns[0]} Positional Encoding: {psnl_encs[0].tolist()}\")\nprint(f\"{op_ip_tkns[1]} Positional Encoding: {psnl_encs[1].tolist()}\")","metadata":{"execution":{"iopub.status.busy":"2024-08-07T07:18:15.183044Z","iopub.execute_input":"2024-08-07T07:18:15.183467Z","iopub.status.idle":"2024-08-07T07:18:15.196582Z","shell.execute_reply.started":"2024-08-07T07:18:15.183417Z","shell.execute_reply":"2024-08-07T07:18:15.195556Z"},"trusted":true},"execution_count":64,"outputs":[{"name":"stdout","text":"Word Tokens: ['नमस्ते,', 'आप', 'कैसे', 'हैं?']\nWord to Index: [0, 1, 2, 3]\n\n********************************************************************************************************************\n\nनमस्ते, embedding: [0.16302567720413208, -0.13589109480381012, -0.3482878804206848, 0.545319676399231, 0.6449902057647705, 0.6906088590621948, 1.2094029188156128, 0.946586549282074]\nआप embedding: [-0.0340677835047245, -1.6508357524871826, -0.36994829773902893, 1.3680638074874878, 1.79978346824646, -0.2353883981704712, 0.8821811079978943, -0.6579354405403137]\n\n********************************************************************************************************************\n\nनमस्ते, Positional Encoding: [0.16302567720413208, 0.8641089051961899, -0.3482878804206848, 1.545319676399231, 0.6449902057647705, 1.6906088590621948, 1.2094029188156128, 1.946586549282074]\nआप Positional Encoding: [0.807403201303172, -1.1105334466190429, -0.2701148810922008, 2.3630679727655135, 1.8097833015806266, 0.7645616022461941, 0.8831811078312276, 0.34206405945972795]\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Masked (MultiHead Attention)","metadata":{}},{"cell_type":"markdown","source":"##### Same as in Encoder. There is only one difference, when we scale dot product of Query vectors and Key vectors, we apply mask matrix on resultant dot product matrix also.","metadata":{}},{"cell_type":"code","source":"# create a mask matrix (for inference only)\nmask = torch.full((len(op_ip_tkns), len(op_ip_tkns)), fill_value=float('-inf'), dtype=torch.float64)\nmask = torch.triu(mask, diagonal=1)","metadata":{"execution":{"iopub.status.busy":"2024-08-07T07:20:08.862386Z","iopub.execute_input":"2024-08-07T07:20:08.862774Z","iopub.status.idle":"2024-08-07T07:20:08.868691Z","shell.execute_reply.started":"2024-08-07T07:20:08.862744Z","shell.execute_reply":"2024-08-07T07:20:08.867545Z"},"trusted":true},"execution_count":67,"outputs":[]},{"cell_type":"code","source":"'''*****************************************************: First Head :*****************************************************'''\n##### Wq, Wk, Wv matrix of parameters for generating the Q, K, V vectors\nWq_1 = nn.Linear(d_model, d_model, dtype=torch.float64)\nWk_1 = nn.Linear(d_model, d_model, dtype=torch.float64)\nWv_1 = nn.Linear(d_model, d_model, dtype=torch.float64)\n\nQ_1, K_1, V_1 = [], [], []                                                   # Matrix for all Query, Key and Value vectors\nfor ebd in psnl_encs:\n    q = Wq_1(ebd)\n    Q_1.append(q)\n    \n    k = Wk_1(ebd)\n    K_1.append(k)\n    \n    v = Wv_1(ebd)\n    V_1.append(v)\n\nQ_1 = torch.stack(Q_1, dim=0)                                              # Stacked all Query vector as matrix\nK_1 = torch.stack(K_1, dim=0)                                              # Stacked all Key vector as matrix\nV_1 = torch.stack(V_1, dim=0)                                              # Stacked all Value vector as matrix\n\nd_k = d_model                                                          # dimensionality of Key vector\n\n# calculate QK_T\nQK_T_1 = torch.matmul(Q_1, torch.t(K_1))                \nsld_QK_T_1 = QK_T_1/math.sqrt(d_k)                                         # scaled dot product of QK_T by sqrt(d_k)\n\n# mask matrix apply\nsld_QK_T_1 = sld_QK_T_1 + mask\n\nsoft_QK_T_1 = torch.softmax(sld_QK_T_1, dim=-1)                            # apply softmax\nself_attn_1 = torch.matmul(soft_QK_T_1, V_1)         \n'''***************************************************: First Head End :***************************************************'''\n\n'''*****************************************************: Second Head :****************************************************'''\n##### Wq, Wk, Wv matrix of parameters for generating the Q, K, V vectors\nWq_2 = nn.Linear(d_model, d_model, dtype=torch.float64)\nWk_2 = nn.Linear(d_model, d_model, dtype=torch.float64)\nWv_2 = nn.Linear(d_model, d_model, dtype=torch.float64)\n\nQ_2, K_2, V_2 = [], [], []                                                   # Matrix for all Query, Key and Value vectors\nfor ebd in psnl_encs:\n    q = Wq_2(ebd)\n    Q_2.append(q)\n    \n    k = Wk_2(ebd)\n    K_2.append(k)\n    \n    v = Wv_2(ebd)\n    V_2.append(v)\n\nQ_2 = torch.stack(Q_2, dim=0)                                              # Stacked all Query vector as matrix\nK_2 = torch.stack(K_2, dim=0)                                              # Stacked all Key vector as matrix\nV_2 = torch.stack(V_2, dim=0)                                              # Stacked all Value vector as matrix\n\nd_k = d_model                                                          # dimensionality of Key vector\n\n# calculate QK_T\nQK_T_2 = torch.matmul(Q_2, torch.t(K_2))                \nsld_QK_T_2 = QK_T_2/math.sqrt(d_k)                                   # scaled dot product of QK_T by sqrt(d_k)\n\n# mask matrix apply\nsld_QK_T_2 = sld_QK_T_2 + mask\n\nsoft_QK_T_2 = torch.softmax(sld_QK_T_2, dim=-1)                            # apply softmax\nself_attn_2 = torch.matmul(soft_QK_T_2, V_2)         \n'''***************************************************: Second Head End :**************************************************'''\n\n# concatenate both the self attention embeddings\nct_attn = torch.cat((self_attn_1, self_attn_2), 1)\n\n# apply linear transformation\nW_c = nn.Linear(ct_attn.shape[1], d_model, dtype=torch.float64)\n\nmultihead_attn = W_c(ct_attn)\n\nprint(f\"MultiHead Attention on {op_ip_tkns[0]}: {multihead_attn[0].tolist()}\")\nprint()\nprint(f\"MultiHead Attention on {op_ip_tkns[1]}: {multihead_attn[1].tolist()}\")","metadata":{"execution":{"iopub.status.busy":"2024-08-07T07:20:10.770029Z","iopub.execute_input":"2024-08-07T07:20:10.770743Z","iopub.status.idle":"2024-08-07T07:20:10.790038Z","shell.execute_reply.started":"2024-08-07T07:20:10.770708Z","shell.execute_reply":"2024-08-07T07:20:10.788981Z"},"trusted":true},"execution_count":68,"outputs":[{"name":"stdout","text":"MultiHead Attention on नमस्ते,: [0.19808594961956605, 0.16539107406989303, 0.16047227468059666, 0.8443892117467038, 0.3126989019256736, -0.7121538366547243, -0.29480363633604906, 0.3437514303539883]\n\nMultiHead Attention on आप: [0.4279334990665706, 0.08269069198801696, 0.14926783603924776, 0.5763281096211011, 0.22916804844579108, -0.715859526398316, -0.12981713852731874, 0.3195667444414096]\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Addition & Normalization","metadata":{}},{"cell_type":"code","source":"# Normalize(O/P MultiHead Attention + Positional Encodings)\nadd_attn = multihead_attn + psnl_encs\n\n# normalization layer\nnorm_l = nn.LayerNorm(d_model, dtype=torch.float64)\n\nnorm_ebds = norm_l(add_attn)\n\nprint(f\"Normalized Embedding of {sne_tkns[0]}: {norm_ebds[0].tolist()}\")\nprint()\nprint(f\"Normalized Embedding of {sne_tkns[1]}: {norm_ebds[1].tolist()}\")","metadata":{"execution":{"iopub.status.busy":"2024-08-07T07:20:23.562301Z","iopub.execute_input":"2024-08-07T07:20:23.562698Z","iopub.status.idle":"2024-08-07T07:20:23.571441Z","shell.execute_reply.started":"2024-08-07T07:20:23.562669Z","shell.execute_reply":"2024-08-07T07:20:23.570256Z"},"trusted":true},"execution_count":69,"outputs":[{"name":"stdout","text":"Normalized Embedding of This: [-0.8926722070909469, -0.0759974170179957, -1.5633826268360298, 1.5859829586956378, -0.16374001195503973, -0.13836703981955928, -0.21638960381250613, 1.4645659478364395]\n\nNormalized Embedding of were: [0.3563367313873898, -1.5672253138521985, -0.7963352643316063, 1.804681423117092, 1.039359297566334, -0.6522290366756707, -0.05331017057177913, -0.13127766663956061]\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Cross Attention","metadata":{}},{"cell_type":"markdown","source":"##### Cross attention takes Key and Value vector from encoder and apply the attention on Q(decoders previous step output), K, V vectors","metadata":{}},{"cell_type":"code","source":"encoder_ip = e_norm_ebds                  # encoder input","metadata":{"execution":{"iopub.status.busy":"2024-08-07T07:21:39.887185Z","iopub.execute_input":"2024-08-07T07:21:39.887946Z","iopub.status.idle":"2024-08-07T07:21:39.894413Z","shell.execute_reply.started":"2024-08-07T07:21:39.887904Z","shell.execute_reply":"2024-08-07T07:21:39.893370Z"},"trusted":true},"execution_count":71,"outputs":[]},{"cell_type":"code","source":"'''*****************************************************: First Head :*****************************************************'''\n##### Wq, Wk, Wv matrix of parameters for generating the Q, K, V vectors\nWq = nn.Linear(d_model, d_model, dtype=torch.float64)\nWk = nn.Linear(d_model, d_model, dtype=torch.float64)\nWv = nn.Linear(d_model, d_model, dtype=torch.float64)\n\nQ_1, K_1, V_1 = [], [], []\nfor ebd in encoder_ip:\n    k = Wk(ebd)\n    K_1.append(k)\n    \n    v = Wv(ebd)\n    V_1.append(v)\n    \nfor ebd in norm_ebds:\n    q = Wq(q)\n    Q_1.append(q)\n    \nQ_1 = torch.stack(Q_1, dim=0)                                              # Stacked all Query vector as matrix\nK_1 = torch.stack(K_1, dim=0)                                              # Stacked all Key vector as matrix\nV_1 = torch.stack(V_1, dim=0)                                              # Stacked all Value vector as matrix\n\nd_k = K_1.size()[1]                                                        # dimensionality of Key vector\n\n# calculate QK_T\nQK_T_1 = torch.matmul(Q_1, torch.t(K_1))                \nsld_QK_T_1 = QK_T_1/math.sqrt(d_k)                                         # scaled dot product of QK_T by sqrt(d_k)\n\nsoft_QK_T_1 = torch.softmax(sld_QK_T_1, dim=-1)                            # apply softmax\nself_attn_1 = torch.matmul(soft_QK_T_1, V_1)         \n'''***************************************************: First Head End :***************************************************'''\n\n'''*****************************************************: Second Head :*****************************************************'''\n##### Wq, Wk, Wv matrix of parameters for generating the Q, K, V vectors\nWq = nn.Linear(d_model, d_model, dtype=torch.float64)\nWk = nn.Linear(d_model, d_model, dtype=torch.float64)\nWv = nn.Linear(d_model, d_model, dtype=torch.float64)\n\nQ_2, K_2, V_2 = [], [], []\nfor ebd in encoder_ip:\n    k = Wk(ebd)\n    K_2.append(k)\n    \n    v = Wv(ebd)\n    V_2.append(v)\n    \nfor ebd in norm_ebds:\n    q = Wq(q)\n    Q_2.append(q)\n    \nQ_2 = torch.stack(Q_2, dim=0)                                              # Stacked all Query vector as matrix\nK_2 = torch.stack(K_2, dim=0)                                              # Stacked all Key vector as matrix\nV_2 = torch.stack(V_2, dim=0)                                              # Stacked all Value vector as matrix\n\nd_k = K_2.size()[1]                                                        # dimensionality of Key vector\n\n# calculate QK_T\nQK_T_2 = torch.matmul(Q_2, torch.t(K_2))                \nsld_QK_T_2 = QK_T_2/math.sqrt(d_k)                                         # scaled dot product of QK_T by sqrt(d_k)\n\nsoft_QK_T_2 = torch.softmax(sld_QK_T_2, dim=-1)                            # apply softmax\nself_attn_2 = torch.matmul(soft_QK_T_2, V_2)         \n'''***************************************************: Second Head End:***************************************************'''\n\n# concatenate both the self attention embeddings\nct_attn = torch.cat((self_attn_1, self_attn_2), 1)\n\n# apply linear transformation\nW_c = nn.Linear(ct_attn.shape[1], d_model, dtype=torch.float64)\n\nmultihead_attn = W_c(ct_attn)\n\nprint(f\"MultiHead Attention on {op_ip_tkns[0]}: {multihead_attn[0].tolist()}\")\nprint()\nprint(f\"MultiHead Attention on {op_ip_tkns[1]}: {multihead_attn[1].tolist()}\")\n\n# Normalize(O/P MultiHead Attention + Positional Encodings)\nadd_attn = multihead_attn + norm_ebds\n\n# normalization layer\nnorm_l = nn.LayerNorm(d_model, dtype=torch.float64)\n\nnorm_ebds = norm_l(add_attn)\n\nprint(f\"Normalized Embedding of {op_ip_tkns[0]}: {norm_ebds[0].tolist()}\")\nprint()\nprint(f\"Normalized Embedding of {op_ip_tkns[1]}: {norm_ebds[1].tolist()}\")","metadata":{"execution":{"iopub.status.busy":"2024-08-07T07:37:54.283918Z","iopub.execute_input":"2024-08-07T07:37:54.284339Z","iopub.status.idle":"2024-08-07T07:37:54.305905Z","shell.execute_reply.started":"2024-08-07T07:37:54.284301Z","shell.execute_reply":"2024-08-07T07:37:54.304750Z"},"trusted":true},"execution_count":77,"outputs":[{"name":"stdout","text":"MultiHead Attention on नमस्ते,: [0.19412608319423683, -0.4134067730647788, -0.44157129144725205, 0.276438487789221, -0.06861453459434408, -0.13484692236640433, -0.04966532369715215, -0.26276689295352923]\n\nMultiHead Attention on आप: [0.2425023851522156, -0.3920071292916776, -0.4463137353767231, 0.25749483058432004, -0.07412023114123495, -0.14043064094672436, -0.07044489287986477, -0.26863468648471495]\nNormalized Embedding of नमस्ते,: [-0.5305889123318833, -0.34122555433786445, -1.7134495770644247, 1.7881876715772989, -0.10848512403299257, -0.1454804602121999, -0.13899845623729706, 1.190040412639363]\n\nNormalized Embedding of आप: [0.5891429782951291, -1.5324944693208842, -0.9381677538780204, 1.8028192951038151, 0.8930312145483321, -0.5649513779909473, -0.010168978360420324, -0.23921090839700387]\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Feed Forward + Addition & Normalization","metadata":{}},{"cell_type":"code","source":"# 2 layer feed forward network\n# 1 layer activation ---> relu\n# 2 lauer activation ---> linear\nfc1 = nn.Linear(d_model, 2048, dtype=torch.float64)\nfc2 = nn.Linear(2048, d_model, dtype=torch.float64)\nfc1_atv = nn.ReLU()\n\nfc_ebds = []\nfor ebd in norm_ebds:\n    fc_ebd = fc2(fc1_atv(fc1(ebd)))\n    \n    fc_ebds.append(fc_ebd)\nfc_ebds = torch.stack(fc_ebds, dim=0)\n\n# Normalized Embeddings + FC Network Embedding\nebds = norm_ebds + fc_ebds\n\n# Normalized Embeddings\nnorm_l = nn.LayerNorm(d_model, dtype=torch.float64)\nd_norm_ebds = norm_l(ebds)\nprint(f\"Normalized Embedding of {op_ip_tkns[0]}: {d_norm_ebds[0].tolist()}\")\nprint()\nprint(f\"Normalized Embedding of {op_ip_tkns[1]}: {d_norm_ebds[1].tolist()}\")","metadata":{"execution":{"iopub.status.busy":"2024-08-07T07:53:23.854948Z","iopub.execute_input":"2024-08-07T07:53:23.855374Z","iopub.status.idle":"2024-08-07T07:53:23.867272Z","shell.execute_reply.started":"2024-08-07T07:53:23.855340Z","shell.execute_reply":"2024-08-07T07:53:23.866131Z"},"trusted":true},"execution_count":79,"outputs":[{"name":"stdout","text":"Normalized Embedding of नमस्ते,: [-0.7225607102665331, -0.8623719294065467, -1.3742873563282956, 1.8788633493526363, -0.08738754894528272, -0.07391608981899199, 0.10538202841485675, 1.1362782569981573]\n\nNormalized Embedding of आप: [0.5968812457273729, -1.7655305946243558, -0.4309792128108882, 1.6987930322288112, 0.9172430057869435, -0.7017817356034783, 0.031860181011967276, -0.3464859217163721]\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Linear + Softmax Layer","metadata":{}},{"cell_type":"code","source":"d_norm_ebds","metadata":{"execution":{"iopub.status.busy":"2024-08-07T07:55:20.319516Z","iopub.execute_input":"2024-08-07T07:55:20.319906Z","iopub.status.idle":"2024-08-07T07:55:20.328320Z","shell.execute_reply.started":"2024-08-07T07:55:20.319874Z","shell.execute_reply":"2024-08-07T07:55:20.327440Z"},"trusted":true},"execution_count":82,"outputs":[{"execution_count":82,"output_type":"execute_result","data":{"text/plain":"tensor([[-0.7226, -0.8624, -1.3743,  1.8789, -0.0874, -0.0739,  0.1054,  1.1363],\n        [ 0.5969, -1.7655, -0.4310,  1.6988,  0.9172, -0.7018,  0.0319, -0.3465],\n        [ 1.9808, -0.7952,  0.1023, -0.4037,  0.3948, -1.6221, -0.2892,  0.6323],\n        [-0.8660, -1.7977, -0.1495,  1.7839,  0.0571,  0.5224, -0.2422,  0.6920]],\n       dtype=torch.float64, grad_fn=<NativeLayerNormBackward0>)"},"metadata":{}}]},{"cell_type":"code","source":"fc = nn.Linear(d_model, vocab_size, dtype=torch.float64)\nprbs = torch.softmax(fc(d_norm_ebds), dim=-1)\n\n\nmax_indices = torch.argmax(prbs, dim=1)\nprint(f\"Maximum probability index: {max_indices}\")","metadata":{"execution":{"iopub.status.busy":"2024-08-07T08:02:06.053670Z","iopub.execute_input":"2024-08-07T08:02:06.054589Z","iopub.status.idle":"2024-08-07T08:02:06.061588Z","shell.execute_reply.started":"2024-08-07T08:02:06.054552Z","shell.execute_reply":"2024-08-07T08:02:06.060392Z"},"trusted":true},"execution_count":91,"outputs":[{"name":"stdout","text":"Maximum probability index: tensor([1, 3, 0, 1])\n","output_type":"stream"}]},{"cell_type":"markdown","source":"<center style=\"font-size: 25px; font-family: Times New Roman; font-weight: bold\">Output Probability Index, Maping to Words</center>","metadata":{}},{"cell_type":"code","source":"trnl = \"\"\nfor index in max_indices.tolist():\n    trnl += r_tgt_dictionary[index] + \" \"\n\nprint(f\"English Sentence: {english[0]}\")\nprint(f\"Hindi Sentence(Orignal): {hindi[0]}\")\nprint()\nprint(f\"Hindi Sentence(Generated): {trnl}\")","metadata":{"execution":{"iopub.status.busy":"2024-08-07T08:09:06.452834Z","iopub.execute_input":"2024-08-07T08:09:06.453214Z","iopub.status.idle":"2024-08-07T08:09:06.459126Z","shell.execute_reply.started":"2024-08-07T08:09:06.453185Z","shell.execute_reply":"2024-08-07T08:09:06.457940Z"},"trusted":true},"execution_count":101,"outputs":[{"name":"stdout","text":"English Sentence: Hello, how are you?\nHindi Sentence(Orignal): नमस्ते, आप कैसे हैं?\n\nHindi Sentence(Generated): आप हैं? नमस्ते, आप \n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{"id":"twQhP_BkS4Op"},"execution_count":null,"outputs":[]}]}